{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos de Clasificación (Parte I)\n",
    "## Actividad 4: Modelos de clasificación\n",
    "### Sebastián Contreras Zambrano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para poder realizar esta actividad debes haber revisado la lectura correspondiente a lasemana.\n",
    "* Crea una carpeta de trabajo y guarda todos los archivos correspondientes (notebook y csv).\n",
    "* Una vez terminada la actividad, comprime la carpeta y sube el .zip a la sección correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre este ejemplo\n",
    "* En esta sesión trabajaremos con una base de datos sobre clientes morosos de un banco.\n",
    "Dentro de ésta se registran las siguientes observaciones:\n",
    "* `default`: Variable Binaria. Registra si el cliente entró en morosidad o no.\n",
    "* `income`: Ingreso promedio declarado por el cliente.\n",
    "* `balance`: total del sando en la cuenta de crédito.\n",
    "* `student`: Variable binaria. Registra si el cliente es estudiante o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preparación de ambiente de trabajo\n",
    "* Importe los módulos básicos para el análisis de datos.Importe las clases `LabelEncoder`, `StandardScaler` y `LabelBinarizer` de `preprocessing`\n",
    "* Importe las funciones `train_test_split` y `cross_val_score` de `model_selection`\n",
    "* Importe la función `classification_report` de metrics\n",
    "* Importe las clases `LinearDiscriminantAnalysis` y `Quadratic DiscriminantAnalysis`.\n",
    "* Agregue la base de datos en el ambiente de trabajo.\n",
    "* Inspeccione la distribución de cada atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('default_credit.csv')\n",
    "df = df.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "def cr_to_df(y_true,y_pred, avg_measures=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función que retorna un Dataframe de pandas a partir de un classification report de la librería sklearn, módulo metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    cr = classification_report(y_true, y_pred)\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "            \n",
    "    tmp_df = pd.DataFrame(D_class_data).T\n",
    "    columnsTitles = ['precision', 'recall', 'f1-score', 'support']\n",
    "    tmp_df = tmp_df.reindex(columns=columnsTitles)\n",
    "    \n",
    "    if avg_measures is False:\n",
    "        tmp_df = tmp_df.drop([' micro avg', ' macro avg','weighted avg'])\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr_df_to_plt(df_cr):\n",
    "\n",
    "    for index, (colname, serie) in enumerate (df_cr.iteritems()):\n",
    "        plt.subplot(2,2,index+1)\n",
    "        sc = sns.scatterplot(x = df_cr[colname].index, y=df_cr[colname].values, \n",
    "                         palette='dodgerblue', s=50)\n",
    "        for a,b in zip(df_cr[colname].index,df_cr[colname].values):\n",
    "            plt.text(a, b, str(b), fontweight ='bold')\n",
    "\n",
    "        if colname != 'support':\n",
    "            sc.set(ylim=(0, 1))\n",
    "        else:\n",
    "            sc.set(ylim=(0, None))\n",
    "        plt.title(colname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Modelo base\n",
    "* Recuerde que los modelos de `sklearn` no soportan datos que no sean numéricos.\n",
    "* Transforme los atributos pertinentes con `LabelEncoder`.\n",
    "* Genere muestras de validación y entrenamiento, reservando un 33% de los datos como validación.\n",
    "* Genere un modelo con `LinearDiscriminantAnalysis` sin modificar los hiperparámetros.\n",
    "* Genere métricas de evaluación utilizando `classification_report`.\n",
    "* Comente sobre cuál es el desempeño del modelo en cada clase, así como en general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no recomendable para el vector objetivo!\n",
    "target_label = df['default'].unique()\n",
    "df['default'] = LabelEncoder().fit_transform(df['default'])\n",
    "\n",
    "target_label = df['student'].unique()\n",
    "df['student'] = LabelEncoder().fit_transform(df['student'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for index, (colname, serie) in enumerate (df.iteritems()):\n",
    "    plt.subplot(2, 2, index+1)\n",
    "    sns.distplot(serie, color='dodgerblue')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mat, X_test_mat, y_train_vec, y_test_vec = train_test_split(\n",
    "    df.loc[:, 'student':'income'],\n",
    "    df['default'],\n",
    "    test_size=.33,\n",
    "    random_state=250992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(X_train_mat, y_train_vec)\n",
    "y_hat = lda_model.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_1 = cr_to_df(y_test_vec, y_hat)\n",
    "display (metricas_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la tabla se pueden generar las siguientes observaciones:\n",
    "\n",
    "* La métrica `Precision` indica que el modelo para $y_{i}=0$ tiene un __98%__ de identificaciones correctas, mientras que para $y_{i}=1$ un __75%__.\n",
    "\n",
    "\n",
    "* La métrica `Recall` indica que un __26%__ de positivos reales se identificó correctamente, mientras que el __100%__ de negativos reales se identificaron de manera correcta. \n",
    "\n",
    "\n",
    "* La métrica `F1` indica que el modelo tiene un __99%__ de éxito para clasificar la categoría $y_{i}=0$ mientras que un __39%__ para clasificar a $y_{i}=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test_vec, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La tabla resultante permite observar las categorías predichas con las observadas. La diagonal principal reporta los casos exitosamente predichos. Una de las primeras medidas de desempeño es medir el porcentaje de casos predichos correctamente por sobre el total de casos. Esta medida se conoce como __Accuracy (Exactitud)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "cr_df_to_plt(metricas_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Refactorización 1 - información a priori\n",
    "* Dado que trabajamos con modelos generativos, podemos incluír información exógena. Para este caso agregaremos dos distribuciones:\n",
    "    * Asumamos que hay un 50/50 de morosos y no morosos.\n",
    "    * Asumamos que hay un 60/40 de morosos y no morosos.\n",
    "* Por cada modelo, reporte las métricas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_2 = LinearDiscriminantAnalysis(priors=[.5,.5])\n",
    "lda_model_2.fit(X_train_mat, y_train_vec)\n",
    "y_hat_2 = lda_model_2.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_2 = cr_to_df(y_test_vec, y_hat_2)\n",
    "display (metricas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "cr_df_to_plt(metricas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_3 = LinearDiscriminantAnalysis(priors=[.6,.4])\n",
    "lda_model_3.fit(X_train_mat, y_train_vec)\n",
    "y_hat_3 = lda_model_3.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_3 = cr_to_df(y_test_vec, y_hat_3)\n",
    "display (metricas_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "cr_df_to_plt(metricas_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones:\n",
    "\n",
    "Al observar los cambios realizados en los hiperparámetros de los modelos LDA, podemos apreciar que la métrica `recall` aumentó considerablemente (un __65%__ para el modelo con modificación del a prori en __50/50__ de morosos y no morosos y un __62%__ para los que a prori se asumió que __60/40__ de morosos y no morosos).\n",
    "\n",
    "Pero esto condujo al modelo a perder hasta un __60%__ de métrica de `Precision` para la categoría $y_{i}=1$, lo cual significa que el modelo está perdiendo capacidad para identificar correctamente esta categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecicio 4: Refactorización 2 - oversampling\n",
    "* Uno de los problemas más graves de esta base de datos, es el fuerte desbalance entre clases. Ahora generaremos observaciones sintéticas mediante __SMOTE__ (Synthetic MinorityOversampling Technique). Para ello, debemos agregar el paquete a nuestro ambiente virtual.En nuestro terminal agregamos `conda install -c conda-forge imbalanced-learn`.Incorpore SMOTE en el ambiente de trabajo con la siguiente sintáxis `from imblearn.over_sampling import SMOTE`.\n",
    "* Para implementar oversampling, debemos generar nuevos objetos que representan nuestra muestra de entrenamiento incrementada artificialmente. Para ello implemente la siguiente sintáxis:\n",
    "\n",
    "```python\n",
    "\n",
    "oversampler = SMOTE(random_state=11238, ratio='minority')\n",
    "\n",
    "X_train_oversamp, y_train_oversamp = oversampler.fit_sample(X_train, y_train)\n",
    "```\n",
    "\n",
    "* Vuelva a entrenar el modelo con los datos aumentados de forma artificial y comente sobre su desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(random_state=250992, ratio='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_oversamp, y_train_oversamp = oversampler.fit_sample(X_train_mat, y_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_4 = LinearDiscriminantAnalysis()\n",
    "lda_model_4.fit(X_train_oversamp, y_train_oversamp)\n",
    "y_hat_4 = lda_model_4.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_4 = cr_to_df(y_test_vec, y_hat_4)\n",
    "display (metricas_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "cr_df_to_plt(metricas_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que las métricas de `precision` y `recall` se ven empeoradas con la imputación de observaciones sintéticas mediante __SMOTE__ al dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Refactorización 3 - QDA\n",
    "* Por último, implemente un modelo QuadraticDiscriminantAnalysis con los datos aumentados artificialmente. \n",
    "* Genere las métricas de desempeño.\n",
    "* Comente a grandes rasgos sobre el mejor modelo en su capacidad predictiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = QuadraticDiscriminantAnalysis().fit(X_train_oversamp, y_train_oversamp)\n",
    "qda_class_pred = qda_model.predict(X_test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_qda = cr_to_df(y_test_vec, qda_class_pred)\n",
    "display (metricas_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set(style=\"darkgrid\")\n",
    "cr_df_to_plt(metricas_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['LDA_no_mod_hiperparametros', 'LDA_a_prori_50/50', 'LDA_a_prori_40/60', 'LDA_con_SMOTE', 'QDA_con_SMOTE']\n",
    "arr_metricas = [metricas_1, metricas_2, metricas_3, metricas_4, metricas_qda]\n",
    "\n",
    "for i in range(len(modelos)):\n",
    "    print (modelos[i])\n",
    "    display(arr_metricas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "\n",
    "Al existir un desbalanceo entre las categorías $y_{i}=1$ e $y_{i}=0$, los modelos no presentan resultados eficientes, independiente la modificación de hiperparámetros o la imputación de datos sintéticos, de hecho, al realizar modificaciones en los modelos, se puede apreciar que empeoran la capacidad para identificar correctamente los casos positivos (`presicion`).\n",
    "\n",
    "\n",
    "En este mismo contexto, la métrica `Recall` mejoró significativamente, lo cual nos indica que para la categoría $y_{i}=1$, el modelo es capaz hasta en un __91%__ de de identificar correctamente los positivos reales.\n",
    "\n",
    "El intercambio en estas métricas es signiticativo, y para elegir el _\"mejor modelo\"_ debemos conocer el contexto de lo que se busca obtener con la implementación de este modelo, por lo cual, el mejor modelo será el que el experto del negocio indique que es más relevante para el banco."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
